import os
from dotenv import load_dotenv
from pathlib import Path
import pymysql
import feedparser
from datetime import datetime

# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
env_path = Path(__file__).resolve().parents[2] / ".env"
print("ğŸ§ª ë¡œë”©í•˜ë ¤ëŠ” .env ê²½ë¡œ:", env_path)
print("ğŸ§ª ì‹¤ì œ ì¡´ì¬ ì—¬ë¶€:", env_path.exists())

load_dotenv(dotenv_path=env_path)
print("DB_USER:", repr(os.getenv("DB_USER")))
print("DB_PASS:", repr(os.getenv("DB_PASS")))

# âœ… DB ì—°ê²°
db = pymysql.connect(
    host=os.getenv("DB_HOST"),
    user=os.getenv("DB_USER"),
    password=os.getenv("DB_PASS"),
    database=os.getenv("DB_NAME"),
    charset='utf8mb4'
)
cursor = db.cursor()

# âœ… RSS ê¸°ë°˜ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬
def crawl_weather_rss():
    rss_url = "https://news.google.com/rss/search?q=ë‚ ì”¨&hl=ko&gl=KR&ceid=KR:ko"
    print("ğŸŒ¤ï¸ RSS ê¸°ë°˜ ë‚ ì”¨ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰!")
    print("ğŸ”— RSS URL:", rss_url)

    feed = feedparser.parse(rss_url)

    for entry in feed.entries:
        title = entry.title
        url = entry.link
        snippet = entry.get("summary", "")
        pub_date = datetime(*entry.published_parsed[:6]) if hasattr(entry, "published_parsed") else datetime.now()

        try:
            cursor.execute("""
                INSERT IGNORE INTO weather_articles (title, url, snippet, published_at)
                VALUES (%s, %s, %s, %s)
            """, (title, url, snippet, pub_date))
            db.commit()
            print("âœ… ì €ì¥ë¨:", title)
        except Exception as e:
            print("âŒ ì €ì¥ ì‹¤íŒ¨:", e)

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    crawl_weather_rss()
